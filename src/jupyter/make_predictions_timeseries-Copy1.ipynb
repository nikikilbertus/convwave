{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import h5py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from collections import OrderedDict\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "sys.path.insert(0, '../train/')\n",
    "from models import TimeSeriesFCN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define some functions that we will be using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data_as_tensor_datasets(file_path, shuffle_data=False, random_seed=42):\n",
    "\n",
    "    # Set the seed for the random number generator\n",
    "    np.random.seed(random_seed)\n",
    "\n",
    "    # Read in the spectrograms from the HDF file\n",
    "    with h5py.File(file_path, 'r') as file:\n",
    "\n",
    "        x = np.array(file['x'])[:10]\n",
    "        y = np.array(file['y_true'])[:10]\n",
    "    \n",
    "    # Convert to torch Tensors\n",
    "    x = torch.from_numpy(x).float()\n",
    "    y = torch.from_numpy(y).float()\n",
    "\n",
    "    # Create TensorDatasets for training, test and validation\n",
    "    tensor_dataset = TensorDataset(x, y)\n",
    "\n",
    "    return tensor_dataset\n",
    "\n",
    "\n",
    "\n",
    "def apply_model(model, data_loader, as_numpy=False):\n",
    "\n",
    "    # Initialize an empty array for our predictions\n",
    "    y_pred = []\n",
    "\n",
    "    # Loop over the test set (in mini-batches) to get the predictions\n",
    "    for mb_idx, mb_data in enumerate(data_loader):\n",
    "\n",
    "        print(mb_idx)\n",
    "        \n",
    "        # Get the inputs and wrap them in a PyTorch variable\n",
    "        inputs, labels = mb_data\n",
    "        inputs = Variable(inputs, volatile=True)\n",
    "        labels = Variable(labels, volatile=True)\n",
    "\n",
    "        # If CUDA is available, run everything on the GPU\n",
    "        if torch.cuda.is_available():\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "        # Make predictions for the given mini-batch\n",
    "        outputs = model.forward(inputs)\n",
    "        outputs = outputs.view((outputs.size()[0], outputs.size()[-1]))\n",
    "\n",
    "        # Stack that onto the previous predictions\n",
    "        y_pred.append(outputs)\n",
    "\n",
    "    # Concatenate the list of Variables to one Variable (this is faster than\n",
    "    # concatenating all intermediate results) and make sure results are float\n",
    "    y_pred = torch.cat(y_pred, dim=0).float()\n",
    "\n",
    "    # If necessary, convert model outputs to numpy array\n",
    "    if as_numpy:\n",
    "        y_pred = y_pred.data.cpu().numpy()\n",
    "\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data into DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_0100_0300 = '../data/predictions/timeseries/baseline/predictions_GW170104_0100_0300_8k.h5'\n",
    "file_path_0250_0500 = '../data/predictions/timeseries/baseline/predictions_GW170104_0250_0500_8k.h5'\n",
    "file_path_0400_0800 = '../data/predictions/timeseries/baseline/predictions_GW170104_0400_0800_8k.h5'\n",
    "file_path_0700_1200 = '../data/predictions/timeseries/baseline/predictions_GW170104_0700_1200_8k.h5'\n",
    "\n",
    "datatensor_0100_0300 = load_data_as_tensor_datasets(file_path_0100_0300)\n",
    "datatensor_0250_0500 = load_data_as_tensor_datasets(file_path_0250_0500)\n",
    "datatensor_0400_0800 = load_data_as_tensor_datasets(file_path_0400_0800)\n",
    "datatensor_0700_1200 = load_data_as_tensor_datasets(file_path_0700_1200)\n",
    "\n",
    "dataloader_0100_0300 = DataLoader(datatensor_0100_0300, batch_size=32)\n",
    "dataloader_0250_0500 = DataLoader(datatensor_0250_0500, batch_size=32)\n",
    "dataloader_0400_0800 = DataLoader(datatensor_0400_0800, batch_size=32)\n",
    "dataloader_0700_1200 = DataLoader(datatensor_0700_1200, batch_size=32)\n",
    "\n",
    "true_labels_0100_0300 = Variable(datatensor_0100_0300.target_tensor, volatile=True)\n",
    "true_labels_0250_0500 = Variable(datatensor_0250_0500.target_tensor, volatile=True)\n",
    "true_labels_0400_0800 = Variable(datatensor_0400_0800.target_tensor, volatile=True)\n",
    "true_labels_0700_1200 = Variable(datatensor_0700_1200.target_tensor, volatile=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the model and set up the net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TimeSeriesFCN()\n",
    "\n",
    "# Load the model weights: A little cumbersome, because we don't have CUDA\n",
    "# and GPU parallelization like during training time\n",
    "weights_file = '../train/weights/timeseries_weights_GW170104_0100_1200_16k.net'\n",
    "state_dict = torch.load(weights_file, map_location=lambda storage, loc: storage)\n",
    "new_state_dict = OrderedDict()\n",
    "for k, v in state_dict.items():\n",
    "    name = k[7:] # remove `module.`\n",
    "    new_state_dict[name] = v\n",
    "\n",
    "model.load_state_dict(new_state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the model on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "predictions_0100_0300 = apply_model(model, dataloader_0100_0300)\n",
    "predictions_0250_0500 = apply_model(model, dataloader_0250_0500)\n",
    "predictions_0400_0800 = apply_model(model, dataloader_0400_0800)\n",
    "predictions_0700_1200 = apply_model(model, dataloader_0700_1200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_weights(labels, threshold):\n",
    "    weights = torch.eq(torch.gt(labels, 0) * torch.lt(labels, threshold), 0)\n",
    "    return weights.float()\n",
    "\n",
    "def loss_function(y_pred, y_true, weights):\n",
    "\n",
    "    # Set up the Binary Cross-Entropy term of the loss\n",
    "    bce_loss = nn.BCELoss(weight=weights)\n",
    "    if torch.cuda.is_available():\n",
    "        bce_loss = bce_loss.cuda()\n",
    "\n",
    "    return bce_loss(y_pred, y_true)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "\n",
    "    # Make sure y_pred is rounded to 0/1\n",
    "    y_pred = torch.round(y_pred)\n",
    "\n",
    "    result = torch.mean(torch.abs(y_true - y_pred), dim=1)\n",
    "    result = torch.mean(result, dim=0)\n",
    "\n",
    "    return 1 - float(result.data.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = get_weights(true_labels_0100_0300, 1.4141823e-22)\n",
    "loss_0100_0300 = loss_function(y_pred=predictions_0100_0300,\n",
    "                               y_true=torch.ceil(true_labels_0100_0300),\n",
    "                               weights=weights)\n",
    "loss_0100_0300 = float(loss_0100_0300.data.cpu().numpy())\n",
    "accuracy_0100_0300 = accuracy(y_pred=predictions_0100_0300 * weights,\n",
    "                              y_true=torch.ceil(true_labels_0100_0300 * weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15090875327587128\n",
      "0.9489949531853199\n"
     ]
    }
   ],
   "source": [
    "print(loss_0100_0300)\n",
    "print(accuracy_0100_0300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
